#!/usr/bin.python
# Simple script to pull down a remote URL for analysis with Thug

import argparse
import sys
import os
import hashlib
import urllib
try:
    import requests
except:
    sys.exit("You need the requests library")


def url_pull(url):
    """Pull down our URLs for review"""
    print "Pulling: " + url 
    md5url = hashlib.md5(url).hexdigest()
    print md5url
    encoded_url = urllib.quote_plus(url) 
    r = requests.get(encoded_url)
    with open(md5url, 'w') as urldump:
        urldump.write(r.text)
    urldump.close()
    print "Dumped URLs to file"


def load_file(afile):
    """Load our URLs from file"""
    with open(afile, 'r') as fh:
        for url in fh:
            clean_url = url.rstrip()
            url_pull(clean_url)


def __main__():
    """Get this party started"""
    parser = argparse.ArgumentParser(description='URL Puller')
    parser.add_argument('--file', '-f', dest='file', help='File with URLs to pull down')
    parser.add_argument('--dest', '-d', dest='dest', help='Directory to dump to')
    parser.add_argument('--version', '-v', action='version', version='%(prog)s 0.1')
    args = parser.parse_args()
    afile = args.file
    adest = args.dest

    if not args.file:
        sys.exit(parser.print_help())
    else:
        load_file(afile)

if __name__ == '__main__':
    __main__()

